# 이상 탐지 방식 상세 설명

## 1. 시간 단위 vs 로그 라인 단위

### ❌ 10분 단위가 아닙니다

현재 모델들은 **10분 단위가 아니라 연속된 10개의 로그 라인**을 하나의 시퀀스로 사용합니다.

### ✅ 시퀀스 길이 (기본값: 10개 로그)

| 모델 | 시퀀스/윈도우 크기 | 단위 |
|------|------------------|------|
| **DeepLog** | `sequence_length=10` | 연속된 10개 로그 라인 |
| **LogAnomaly** | `window_size=10` | 연속된 10개 로그 라인 |
| **LogRobust** | `sequence_length=10` | 연속된 10개 로그 라인 |

**예시**:
```
로그 라인 1: 2025-07-02 15:59:36.514  INFO ... Application : Starting...
로그 라인 2: 2025-07-02 15:59:36.515  INFO ... Application : Started...
로그 라인 3: 2025-07-02 15:59:36.516  INFO ... Application : Running...
...
로그 라인 10: 2025-07-02 15:59:36.523  INFO ... Application : Processing...

→ 이 10개 로그 라인이 하나의 시퀀스
```

### 시간 기반이 아닌 이유

- 로그 발생 빈도가 일정하지 않음 (1초에 100개 vs 1분에 1개)
- 로그 라인 단위가 더 정확한 패턴 학습 가능
- 시간 윈도우는 `log_anomaly_detector.py`의 통계적 방법에서만 사용

---

## 2. 이상 탐지 방식

### ✅ 시계열 이상 탐지입니다

모든 모델은 **로그를 시간 순서대로 정렬**하고, **연속된 로그 시퀀스**를 사용합니다.

### DeepLog: 다음 로그 예측 방식

#### 동작 원리
1. **시퀀스 생성**: 연속된 10개 로그를 하나의 시퀀스로 만듦
2. **다음 로그 예측**: LSTM 모델이 11번째 로그를 예측
3. **이상 판단**: 예측 확률이 낮으면 이상으로 판단

```python
# 시퀀스: 로그 1~10
sequence = [log1, log2, log3, ..., log10]

# 모델이 예측: 다음 로그는 log11이어야 함
predicted = model.predict(sequence)

# 실제 다음 로그: log11
actual = log11

# 예측 확률이 낮으면 이상
anomaly_score = 1 - prediction_probability
if anomaly_score > threshold:
    # 이상으로 판단
```

#### 특징
- **정상 패턴 학습**: 정상 로그만으로 학습하여 정상 실행 경로를 학습
- **예측 오차 기반**: 예측이 틀리면 이상으로 판단
- **재현율 높음**: 거의 모든 이상을 탐지 (99.97%)
- **정밀도 낮음**: 오탐이 많음 (정상도 이상으로 판단)

### LogAnomaly: Z-score 기반 통계적 방법

#### 동작 원리
1. **템플릿 벡터화**: 각 로그 메시지를 템플릿으로 변환 후 벡터화
2. **정상 패턴 학습**: 정상 시퀀스의 평균과 표준편차 계산
3. **Z-score 계산**: 테스트 시퀀스가 정상 패턴과 얼마나 다른지 계산
4. **이상 판단**: Z-score가 임계값(기본 3.0)을 넘으면 이상

```python
# 정상 시퀀스 학습
normal_sequences = [seq1, seq2, seq3, ...]
normal_mean = mean(normal_sequences)  # 정상 패턴 평균
normal_std = std(normal_sequences)     # 정상 패턴 표준편차

# 테스트 시퀀스
test_sequence = [log1, log2, ..., log10]
test_vector = template2vec(test_sequence)

# Z-score 계산
z_score = abs((test_vector - normal_mean) / normal_std)

# Z-score가 3.0을 넘으면 이상
if z_score > 3.0:
    # 이상으로 판단
```

#### 특징
- **통계 기반**: 정상 패턴의 통계적 특성을 학습
- **의미 벡터화**: 템플릿을 벡터로 변환하여 의미적 유사도 계산
- **정확도 높음**: 정상을 잘 구분 (87.71%)
- **재현율 낮음**: 이상을 많이 놓침 (6.75%)

### LogRobust: Attention + Bi-LSTM

#### 동작 원리
1. **시퀀스 생성**: 연속된 10개 로그를 벡터 시퀀스로 변환
2. **양방향 학습**: Bi-LSTM으로 양방향 패턴 학습
3. **Attention**: 중요한 부분에 집중
4. **이상 점수**: 모델이 직접 이상 점수 출력 (0~1)

```python
# 시퀀스 생성
sequence = [encode(log1), encode(log2), ..., encode(log10)]

# Bi-LSTM + Attention
output = model(sequence)  # 0~1 사이의 이상 점수

# 임계값(0.5)을 넘으면 이상
if output > 0.5:
    # 이상으로 판단
```

#### 특징
- **복잡한 패턴 학습**: Attention으로 중요한 부분 강조
- **양방향 학습**: 과거와 미래 정보 모두 활용
- **학습 시간 길음**: Attention 메커니즘으로 인해 학습 시간이 김
- **기본 임계값에서 실패 가능**: 임계값 조정 필요

---

## 3. 시계열 이상 탐지인가?

### ✅ 네, 시계열 이상 탐지입니다

#### 시계열 특징
1. **시간 순서 정렬**: 모든 모델이 로그를 `timestamp` 기준으로 정렬
2. **연속된 시퀀스**: 시간 순서대로 연속된 로그를 시퀀스로 사용
3. **순서 의존성**: 로그의 순서가 중요함 (순서가 바뀌면 다른 패턴)

#### 시계열이 아닌 경우와의 차이
- **시계열 아님**: 각 로그를 독립적으로 분석 (순서 무시)
- **시계열**: 연속된 로그의 패턴을 분석 (순서 중요)

#### 예시
```
정상 패턴:
  로그1: Starting...
  로그2: Initializing...
  로그3: Ready...
  로그4: Processing...

이상 패턴:
  로그1: Starting...
  로그2: Error occurred!  ← 순서가 맞지 않음
  로그3: Initializing...
  로그4: Ready...

→ 시계열 모델은 순서를 고려하여 이상을 탐지
```

---

## 4. 실제 동작 예시

### DeepLog 예시

```python
# 학습 단계
정상 로그 시퀀스:
  [로그1, 로그2, ..., 로그10] → 다음 로그: 로그11 (예측 학습)

# 탐지 단계
테스트 시퀀스:
  [로그1, 로그2, ..., 로그10] → 다음 로그: 로그11 (예측)

예측 확률: 0.95 (높음) → 정상
예측 확률: 0.10 (낮음) → 이상 (예상치 못한 로그)
```

### LogAnomaly 예시

```python
# 학습 단계
정상 시퀀스 벡터들의 평균과 표준편차 계산:
  normal_mean = [0.5, 0.3, 0.8, ...]
  normal_std = [0.1, 0.2, 0.15, ...]

# 탐지 단계
테스트 시퀀스 벡터:
  test_vector = [0.9, 0.1, 0.2, ...]  # 정상과 다름

Z-score = abs((0.9 - 0.5) / 0.1) = 4.0 > 3.0 → 이상
```

### LogRobust 예시

```python
# 학습 단계
정상 시퀀스로 Bi-LSTM + Attention 모델 학습

# 탐지 단계
테스트 시퀀스 입력:
  sequence = [벡터1, 벡터2, ..., 벡터10]

모델 출력:
  anomaly_score = 0.85 > 0.5 → 이상
```

---

## 5. 시퀀스 길이 조정

### 현재 설정
- **기본값**: 10개 로그 라인
- **이유**: 너무 짧으면 패턴을 못 잡고, 너무 길면 메모리 부족

### 조정 방법

```python
# DeepLog
detector = DeepLogDetector(sequence_length=15)  # 10 → 15

# LogAnomaly
detector.train(logs_df, window_size=15)  # 10 → 15

# LogRobust
detector.train(logs_df, sequence_length=15)  # 10 → 15
```

### 시퀀스 길이에 따른 영향
- **짧은 시퀀스 (5개)**: 단기 패턴만 학습, 빠른 탐지
- **긴 시퀀스 (20개)**: 장기 패턴 학습, 더 정확하지만 메모리 많이 사용

---

## 6. 요약

### 시간 단위 vs 로그 라인 단위
- ❌ **10분 단위 아님**
- ✅ **10개 로그 라인 단위** (기본값)

### 이상 탐지 방식
- ✅ **시계열 이상 탐지**
- ✅ **연속된 로그 시퀀스 기반**
- ✅ **시간 순서 중요**

### 모델별 특징
| 모델 | 방식 | 장점 | 단점 |
|------|------|------|------|
| **DeepLog** | 다음 로그 예측 | 재현율 높음 | 오탐 많음 |
| **LogAnomaly** | Z-score 통계 | 정확도 높음 | 이상 탐지율 낮음 |
| **LogRobust** | Attention + Bi-LSTM | 복잡한 패턴 학습 | 학습 시간 길음 |

### 핵심 포인트
1. **시계열 기반**: 로그를 시간 순서대로 정렬하여 연속된 패턴 학습
2. **시퀀스 단위**: 10개 로그 라인을 하나의 시퀀스로 사용 (시간 단위 아님)
3. **정상 패턴 학습**: 정상 로그만으로 학습하여 이상을 찾는 방식 (Unsupervised)

