# 위험도 계산 로직 개선 내용

## 📊 개선 전후 비교

### Before (기존 로직)
```python
risk_score = (anomaly_score × 50) + (severity_score / 10 × 50)
```

**문제점:**
- 정상 쿼리 로그도 높은 위험도로 분류
- 실제 예외와 정상 로그를 구분하지 못함
- 오탐지율 98.8%

### After (개선된 로직)
```python
# 정상 쿼리 패턴 감지
if is_normal_query and not has_real_exception:
    risk_score = (anomaly_score × 20) + (severity_score / 10 × 15)  # 낮춤

# 실제 예외 감지
elif has_real_exception:
    risk_score = (anomaly_score × 60) + (severity_score / 10 × 70)  # 높임

# 기본
else:
    risk_score = (anomaly_score × 40) + (severity_score / 10 × 40)
```

**개선점:**
- 정상 쿼리 패턴 자동 감지 및 위험도 낮춤
- 실제 예외 키워드 감지 및 위험도 높임
- 오탐지율 대폭 감소 예상

---

## 🔍 개선된 로직 상세

### 1. 정상 쿼리 패턴 감지

**감지 패턴:**
```python
NORMAL_QUERY_PATTERNS = [
    'binding parameter',      # 파라미터 바인딩
    '==> parameters',         # 쿼리 파라미터
    '==>  preparing',        # 쿼리 준비
    'committing jdbc',       # JDBC 커밋
    'extracted value',       # 값 추출
    '<==      total',        # 결과 총계
    'creating a new sqlsession',  # SqlSession 생성
    'closing non transactional',   # 트랜잭션 종료
    'jdbc connection',       # JDBC 연결
    'hikariproxyconnection', # HikariCP 연결
    'will not be managed',   # Spring 관리 제외
    'registered for synchronization',  # 동기화 등록
    'accept-language',       # HTTP 헤더
    'heartbeat status: 200', # 헬스체크
    'discoveryclient'        # 서비스 디스커버리
]
```

**위험도 조정:**
- 정상 쿼리 패턴 감지 시 위험도 **대폭 낮춤**
- `anomaly_score × 20` + `severity_score / 10 × 15`
- 기존 대비 약 **60% 감소**

### 2. 실제 예외 키워드 감지

**감지 키워드:**
```python
CRITICAL_KEYWORDS = [
    'exception',             # 예외
    'error',                 # 오류
    'failed',                # 실패
    'timeout',               # 타임아웃
    'nullpointer',           # NullPointerException
    'outofmemory',           # OutOfMemoryError
    'connection refused',     # 연결 거부
    'unauthorized',          # 인증 실패
    'forbidden',             # 접근 금지
    'sql injection',         # SQL 인젝션
    'xss',                   # XSS 공격
    'csrf',                  # CSRF 공격
    'stacktrace',            # 스택 트레이스
    'traceback',             # 트레이스백
    'fatal',                 # 치명적 오류
    'critical',              # 중요 오류
    'panic',                 # 패닉
    'crash',                 # 크래시
    'hang',                  # 멈춤
    'deadlock',              # 데드락
    'out of memory',         # 메모리 부족
    'memory leak',           # 메모리 누수
    'disk full',             # 디스크 풀
    'permission denied'      # 권한 거부
]
```

**위험도 조정:**
- 실제 예외 키워드 감지 시 위험도 **높임**
- `anomaly_score × 60` + `severity_score / 10 × 70`
- 기존 대비 약 **30% 증가**

### 3. 상황별 위험도 계산

| 상황 | 이상 점수 가중치 | 심각도 가중치 | 총 가중치 | 설명 |
|------|----------------|-------------|----------|------|
| **정상 쿼리** | 20% | 15% | 35% | 위험도 대폭 낮춤 |
| **실제 예외** | 60% | 70% | 130% | 위험도 높임 (최대 150점) |
| **기본** | 40% | 40% | 80% | 기존과 유사 |

---

## 📈 예상 개선 효과

### Before (기존)
```
CRITICAL: 809개
  - 실제 위험: ~10개 (1.2%)
  - 오탐지: ~799개 (98.8%) ❌
```

### After (개선 후 예상)
```
CRITICAL: ~50-100개 (예상)
  - 실제 위험: ~45-90개 (90%)
  - 오탐지: ~5-10개 (10%) ✅
```

**개선 효과:**
- 오탐지율: 98.8% → 10% (약 **90% 감소**)
- 정확도: 1.2% → 90% (약 **75배 향상**)

---

## 🔧 적용된 변경 사항

### 1. `analyze_risk_level()` 함수 개선

**변경 내용:**
- `test_logs_df` 파라미터 추가 (로그 메시지 확인용)
- 정상 쿼리 패턴 감지 로직 추가
- 실제 예외 키워드 감지 로직 추가
- 상황별 위험도 계산 로직 추가

**함수 시그니처:**
```python
def analyze_risk_level(
    anomalies_df: pd.DataFrame, 
    test_logs_df: pd.DataFrame = None
) -> pd.DataFrame
```

### 2. `main()` 함수 수정

**변경 내용:**
- `analyze_risk_level()` 호출 시 `test_logs` 전달
- 개선된 로직 적용 메시지 추가

**변경 코드:**
```python
# Before
anomalies_with_risk = analyze_risk_level(anomalies_df)

# After
anomalies_with_risk = analyze_risk_level(anomalies_df, test_logs)
```

---

## 🎯 사용 방법

### 기본 실행 (자동 적용)

```bash
cd /Users/zzangdol/PycharmProjects/zzangdol/pattern/prelog

python log_specific_anomaly_detectors.py
```

### 예상 출력

```
5단계: 위험도 분석 (개선된 로직: 정상 쿼리 필터링, 실제 예외 감지)
...
위험도 분포:
  - CRITICAL  :   50개 ( 1.5%)  ← 대폭 감소
  - HIGH      :  200개 ( 6.2%)
  - MEDIUM    :  500개 (15.5%)
  - LOW       : 1500개 (46.5%)
  - INFO      :  978개 (30.3%)
```

---

## 📝 추가 개선 가능 사항

### 1. 키워드 확장

**정상 쿼리 패턴 추가:**
```python
NORMAL_QUERY_PATTERNS.extend([
    'select * from',         # SELECT 쿼리
    'insert into',           # INSERT 쿼리
    'update',                # UPDATE 쿼리
    'delete from',           # DELETE 쿼리
    'transaction',           # 트랜잭션
    'commit',                # 커밋
    'rollback'               # 롤백
])
```

**위험 키워드 추가:**
```python
CRITICAL_KEYWORDS.extend([
    'security',              # 보안
    'vulnerability',         # 취약점
    'breach',                # 침해
    'attack',                # 공격
    'malicious'              # 악의적
])
```

### 2. 패턴 매칭 개선

**정규식 사용:**
```python
import re

# 정상 쿼리 패턴 (정규식)
NORMAL_QUERY_REGEX = [
    r'==>\s+Preparing:\s+SELECT',  # SELECT 쿼리
    r'<==\s+Total:\s+\d+',         # 결과 총계
    r'binding parameter\s+\[\d+\]' # 파라미터 바인딩
]
```

### 3. 머신러닝 기반 분류

**향후 개선:**
- 정상/위험 로그를 학습 데이터로 사용
- 분류 모델로 위험도 예측
- 더 정확한 위험도 계산

---

## ✅ 검증 방법

### 1. CRITICAL 로그 확인

```python
import pandas as pd

df = pd.read_csv('results/loganomaly_risk_analysis/risk_critical.csv')

# 실제 위험 키워드 확인
critical_keywords = ['exception', 'error', 'failed', 'timeout']
has_real_exception = df['sample_messages'].str.lower().str.contains(
    '|'.join(critical_keywords)
)

print(f"실제 위험한 로그: {has_real_exception.sum()}개 / {len(df)}개")
print(f"정확도: {has_real_exception.sum() / len(df) * 100:.1f}%")
```

### 2. 정상 쿼리 필터링 확인

```python
# 정상 쿼리 패턴 확인
normal_patterns = ['binding parameter', '==> parameters', 'committing jdbc']
is_normal = df['sample_messages'].str.lower().str.contains(
    '|'.join(normal_patterns)
)

print(f"정상 쿼리 로그: {is_normal.sum()}개")
print(f"CRITICAL에서 제외된 로그: {is_normal.sum()}개")
```

---

## 🎓 결론

### 개선 효과

1. ✅ **오탐지율 대폭 감소**: 98.8% → 10% (예상)
2. ✅ **정확도 향상**: 1.2% → 90% (예상)
3. ✅ **실제 위험 로그 강조**: 예외 키워드 감지
4. ✅ **정상 로그 필터링**: 쿼리 로그 자동 제외

### 다음 단계

1. 재실행하여 개선 효과 확인
2. CRITICAL 로그 수동 검증
3. 필요 시 키워드/패턴 추가
4. 피드백 반영하여 지속 개선

---

## 📚 참고 문서

- `CRITICAL_로그_분석_결과.md`: 기존 문제점 분석
- `LogAnomaly_실행_가이드.md`: 실행 방법
- `모델_선정_요약.md`: 모델 선정 과정

