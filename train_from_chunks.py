#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì²­í¬ ë°ì´í„°ì…‹ ìƒì„±ë¶€í„° í•™ìŠµê¹Œì§€ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python train_from_chunks.py
    
ì˜µì…˜:
    --epochs: í•™ìŠµ epoch ìˆ˜ (ê¸°ë³¸: 10, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)
    --batch-size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 64, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
    --chunk-size: ì²­í¬ í¬ê¸° (ê¸°ë³¸: 10000)
    --keep-chunks: ì²­í¬ íŒŒì¼ ìœ ì§€ (ê¸°ë³¸: True, ì¬ì‚¬ìš© ê°€ëŠ¥)
"""

import os
import sys
import argparse
from datetime import datetime
from log_anomaly_detector import SpringBootLogParser
from log_specific_model_comparison import LogSpecificModelComparator

def main():
    """ì²­í¬ ìƒì„±ë¶€í„° í•™ìŠµê¹Œì§€ ì „ì²´ í”„ë¡œì„¸ìŠ¤"""
    parser = argparse.ArgumentParser(description='ì²­í¬ ë°ì´í„°ì…‹ ìƒì„±ë¶€í„° í•™ìŠµê¹Œì§€')
    parser.add_argument('--epochs', type=int, default=10,
                       help='í•™ìŠµ epoch ìˆ˜ (ê¸°ë³¸: 10, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)')
    parser.add_argument('--batch-size', type=int, default=64,
                       help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 64, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )')
    parser.add_argument('--chunk-size', type=int, default=10000,
                       help='íŒŒì‹± ì²­í¬ í¬ê¸° (ê¸°ë³¸: 10000)')
    parser.add_argument('--keep-chunks', action='store_true', default=True,
                       help='ì²­í¬ íŒŒì¼ ìœ ì§€ (ê¸°ë³¸: True)')
    parser.add_argument('--skip-parsing', action='store_true',
                       help='íŒŒì‹± ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ì²­í¬ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)')
    parser.add_argument('--skip-split', action='store_true',
                       help='ë°ì´í„° ë¶„í•  ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ë¶„í• ëœ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)')
    parser.add_argument('--log-dir', type=str, default=None,
                       help='ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸: pattern/prelog/logs/backup)')
    parser.add_argument('--chunk-dir', type=str, default=None,
                       help='ì²­í¬ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: pattern/prelog/chunks)')
    parser.add_argument('--split-dir', type=str, default=None,
                       help='ë¶„í•  ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: pattern/prelog/split_data)')
    parser.add_argument('--models', type=str, nargs='+', default=['deeplog', 'loganomaly'],
                       help='í•™ìŠµí•  ëª¨ë¸ ëª©ë¡ (ê¸°ë³¸: deeplog loganomaly)')
    
    args = parser.parse_args()
    
    # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    script_dir = os.path.dirname(os.path.abspath(__file__))
    log_directory = args.log_dir or os.path.join(script_dir, 'logs', 'backup')
    chunk_dir = args.chunk_dir or os.path.join(script_dir, 'chunks')
    split_dir = args.split_dir or os.path.join(script_dir, 'split_data')
    
    print("=" * 70)
    print("ì²­í¬ ë°ì´í„°ì…‹ ìƒì„±ë¶€í„° í•™ìŠµê¹Œì§€ ì „ì²´ ì›Œí¬í”Œë¡œìš°")
    print("=" * 70)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\nì„¤ì •:")
    print(f"  - ë¡œê·¸ ë””ë ‰í† ë¦¬: {log_directory}")
    print(f"  - ì²­í¬ ë””ë ‰í† ë¦¬: {chunk_dir}")
    print(f"  - ë¶„í•  ë°ì´í„° ë””ë ‰í† ë¦¬: {split_dir}")
    print(f"  - Epoch ìˆ˜: {args.epochs}")
    print(f"  - ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    print(f"  - ì²­í¬ í¬ê¸°: {args.chunk_size:,}")
    print(f"  - í•™ìŠµ ëª¨ë¸: {', '.join(args.models)}")
    print("=" * 70)
    
    # 1ë‹¨ê³„: ë¡œê·¸ íŒŒì‹± ë° ì²­í¬ ìƒì„±
    print("\n" + "=" * 70)
    print("1ë‹¨ê³„: ë¡œê·¸ íŒŒì‹± ë° ì²­í¬ íŒŒì¼ ìƒì„±")
    print("=" * 70)
    
    parser_obj = SpringBootLogParser()
    
    if args.skip_parsing:
        print("â­ï¸  íŒŒì‹± ê±´ë„ˆë›°ê¸° (ê¸°ì¡´ ì²­í¬ íŒŒì¼ ì‚¬ìš©)")
        if not os.path.exists(chunk_dir) or len(os.listdir(chunk_dir)) == 0:
            print("âš ï¸  ì²­í¬ ë””ë ‰í† ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. --skip-parsing ì˜µì…˜ì„ ì œê±°í•˜ì„¸ìš”.")
            return
    else:
        if not os.path.exists(log_directory):
            print(f"âŒ ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {log_directory}")
            return
        
        # ì²­í¬ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(chunk_dir, exist_ok=True)
        print(f"ğŸ“ ì²­í¬ íŒŒì¼ ì €ì¥ ìœ„ì¹˜: {chunk_dir}")
        
        # íŒŒì‹± ìˆ˜í–‰
        print(f"ğŸ“ ë¡œê·¸ íŒŒì¼ íŒŒì‹± ì¤‘...")
        logs_df = parser_obj.parse_directory(
            log_directory,
            max_files=None,
            sample_lines=None,
            chunk_size=args.chunk_size,
            max_total_lines=None,
            save_chunks_to_disk=True,
            chunk_dir=chunk_dir,
            keep_chunks=args.keep_chunks
        )
        
        if logs_df.empty:
            print("âš ï¸  íŒŒì‹±ëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"âœ… íŒŒì‹± ì™„ë£Œ: {len(logs_df):,}ê°œ ë¡œê·¸")
        
        # íŒŒì‹± ë°ì´í„°ë¥¼ ë‹¨ì¼ íŒŒì¼ë¡œ ì €ì¥ (ì„ íƒì )
        parsed_data_path = os.path.join(script_dir, 'parsed_data.parquet')
        print(f"ğŸ’¾ íŒŒì‹± ë°ì´í„° ì €ì¥ ì¤‘: {parsed_data_path}")
        parser_obj.save_parsed_data(logs_df, parsed_data_path)
        print(f"âœ… íŒŒì‹± ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        
        # ë©”ëª¨ë¦¬ í•´ì œ
        del logs_df
        import gc
        gc.collect()
    
    # 2ë‹¨ê³„: ë°ì´í„° ë¶„í•  (ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹)
    print("\n" + "=" * 70)
    print("2ë‹¨ê³„: ë°ì´í„° ë¶„í•  (ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹)")
    print("=" * 70)
    
    if args.skip_split:
        print("â­ï¸  ë°ì´í„° ë¶„í•  ê±´ë„ˆë›°ê¸° (ê¸°ì¡´ ë¶„í•  ë°ì´í„° ì‚¬ìš©)")
        if not os.path.exists(split_dir):
            print("âš ï¸  ë¶„í•  ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. --skip-split ì˜µì…˜ì„ ì œê±°í•˜ì„¸ìš”.")
            return
    else:
        # íŒŒì‹± ë°ì´í„° ë¡œë“œ ë˜ëŠ” ì²­í¬ì—ì„œ ë¡œë“œ
        parsed_data_path = os.path.join(script_dir, 'parsed_data.parquet')
        
        if os.path.exists(parsed_data_path):
            print(f"ğŸ“‚ íŒŒì‹± ë°ì´í„° ë¡œë“œ: {parsed_data_path}")
            input_path = parsed_data_path
        else:
            print(f"ğŸ“‚ ì²­í¬ íŒŒì¼ì—ì„œ ë°ì´í„° ì‚¬ìš©: {chunk_dir}")
            input_path = chunk_dir
        
        # ë¶„í•  ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(split_dir, exist_ok=True)
        print(f"ğŸ“ ë¶„í•  ë°ì´í„° ì €ì¥ ìœ„ì¹˜: {split_dir}")
        
        # ìŠ¤íŠ¸ë¦¬ë° ë¶„í•  ìˆ˜í–‰
        print(f"ğŸ’¡ ìŠ¤íŠ¸ë¦¬ë° ë¶„í•  ëª¨ë“œ: ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„í•  ì¤‘...")
        if os.path.isdir(input_path):
            # ì²­í¬ ë””ë ‰í† ë¦¬ì¸ ê²½ìš°
            print("   ì²­í¬ íŒŒì¼ì—ì„œ ì§ì ‘ ë¶„í• ...")
            # ì²­í¬ íŒŒì¼ì„ í•˜ë‚˜ì”© ì½ì–´ì„œ ë¶„í• 
            chunk_files = parser_obj.get_chunk_files(input_path)
            print(f"   ì´ {len(chunk_files)}ê°œ ì²­í¬ íŒŒì¼ ë°œê²¬")
            
            # ê°„ë‹¨í•œ ë°©ë²•: ì²­í¬ë¥¼ ë¡œë“œí•´ì„œ ë¶„í• 
            # ë” íš¨ìœ¨ì ì¸ ë°©ë²•ì€ prepare_data_streamingì„ ìˆ˜ì •í•´ì•¼ í•¨
            # ì—¬ê¸°ì„œëŠ” parsed_data.parquetê°€ ìˆë‹¤ê³  ê°€ì •
            if os.path.exists(parsed_data_path):
                split_files = parser_obj.prepare_data_streaming(
                    parsed_data_path,
                    split_dir,
                    train_ratio=0.8,
                    valid_ratio=0.2,
                    chunk_size=100000
                )
            else:
                print("âš ï¸  parsed_data.parquet íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì‹±ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
                return
        else:
            # ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš°
            split_files = parser_obj.prepare_data_streaming(
                input_path,
                split_dir,
                train_ratio=0.8,
                valid_ratio=0.2,
                chunk_size=100000
            )
        
        print(f"âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ")
        print(f"   - Train: {split_files.get('train', 'N/A')}")
        print(f"   - Valid: {split_files.get('valid', 'N/A')}")
        print(f"   - Test: {split_files.get('test', 'N/A')}")
    
    # 3ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ
    print("\n" + "=" * 70)
    print("3ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ")
    print("=" * 70)
    
    comparator = LogSpecificModelComparator()
    
    # ë¶„í• ëœ ë°ì´í„° ë¡œë“œ (í•™ìŠµìš©ë§Œ)
    print("ğŸ“‚ í•™ìŠµ ë°ì´í„° ë¡œë“œ ì¤‘...")
    data = comparator.prepare_data_from_files(split_dir, load_only_train=True)
    
    if not data or data.get('train_normal', None) is None or data['train_normal'].empty:
        print("âš ï¸  í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
    print(f"   - Train Normal: {len(data['train_normal']):,}ê°œ")
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
    available_models = []
    for model in args.models:
        if model == 'logrobust':
            try:
                import torch
                available_models.append(model)
                print(f"   âœ… {model.upper()} ì‚¬ìš© ê°€ëŠ¥")
            except ImportError:
                print(f"   âš ï¸  {model.upper()} ì œì™¸ (PyTorch ë¯¸ì„¤ì¹˜)")
        else:
            available_models.append(model)
            print(f"   âœ… {model.upper()} ì‚¬ìš© ê°€ëŠ¥")
    
    if not available_models:
        print("âš ï¸  í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í•™ìŠµ ë¡œê·¸ ë””ë ‰í† ë¦¬ ì„¤ì •
    log_dir = os.path.join(script_dir, 'logs', 'training')
    os.makedirs(log_dir, exist_ok=True)
    
    print(f"\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print(f"   - Epoch: {args.epochs}")
    print(f"   - Batch Size: {args.batch_size}")
    print(f"   ğŸ’¡ í•™ìŠµ ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´ Epoch ìˆ˜ë¥¼ ì¤„ì˜€ìŠµë‹ˆë‹¤.")
    print(f"   ğŸ’¡ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ ë°°ì¹˜ í¬ê¸°ë¥¼ ëŠ˜ë ¸ìŠµë‹ˆë‹¤.")
    
    # ëª¨ë¸ë³„ í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •
    # DeepLogì˜ ê²½ìš° train ë©”ì„œë“œì—ì„œ epochsì™€ batch_sizeë¥¼ ë°›ì„ ìˆ˜ ìˆë„ë¡ ìˆ˜ì • í•„ìš”
    # ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì§„í–‰ (ì‹¤ì œ ì ìš©ì€ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬)
    comparator.train_models(
        data['train_normal'],
        valid_normal_logs=data.get('valid_normal'),
        model_types=available_models,
        log_dir=log_dir,
        epochs=args.epochs,
        batch_size=args.batch_size
    )
    
    if not comparator.trained_systems:
        print("âš ï¸  í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í•™ìŠµ ë°ì´í„° ë©”ëª¨ë¦¬ í•´ì œ
    del data['train_normal']
    if 'train_error' in data:
        del data['train_error']
    if 'valid_normal' in data:
        del data['valid_normal']
    import gc
    gc.collect()
    
    # 4ë‹¨ê³„: ëª¨ë¸ í‰ê°€
    print("\n" + "=" * 70)
    print("4ë‹¨ê³„: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    print("=" * 70)
    
    # í‰ê°€ìš© ë°ì´í„° ë¡œë“œ
    print("ğŸ“‚ í‰ê°€ ë°ì´í„° ë¡œë“œ ì¤‘...")
    test_data = comparator.load_test_data(split_dir)
    
    if test_data['test_logs'].empty:
        print("âš ï¸  í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… í‰ê°€ ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
    print(f"   - Test Logs: {len(test_data['test_logs']):,}ê°œ")
    
    results = comparator.evaluate_models(test_data['test_logs'], test_data['y_test'])
    
    if not results:
        print("âš ï¸  í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 5ë‹¨ê³„: ê²°ê³¼ ë¦¬í¬íŠ¸
    print("\n" + "=" * 70)
    print("5ë‹¨ê³„: ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±")
    print("=" * 70)
    
    output_dir = os.path.join(script_dir, 'results', 'log_specific_comparison')
    os.makedirs(output_dir, exist_ok=True)
    
    comparison_df, best_model = comparator.generate_comparison_report(output_dir=output_dir)
    
    # ìµœì  ëª¨ë¸ ì„ ì •
    best_model_name, best_system = comparator.get_best_model()
    
    print(f"\n{'='*70}")
    print(f"ğŸ† ìµœì¢… ì„ ì •ëœ ëª¨ë¸: {best_model_name.upper()}")
    print(f"{'='*70}")
    
    if best_model_name in results:
        best_metrics = results[best_model_name]
        print(f"\nì„±ëŠ¥ ì§€í‘œ:")
        print(f"   ì •í™•ë„: {best_metrics['accuracy']:.4f} ({best_metrics['accuracy']*100:.2f}%)")
        print(f"   ì •ë°€ë„: {best_metrics['precision']:.4f} ({best_metrics['precision']*100:.2f}%)")
        print(f"   ì¬í˜„ìœ¨: {best_metrics['recall']:.4f} ({best_metrics['recall']*100:.2f}%)")
        print(f"   F1 ì ìˆ˜: {best_metrics['f1_score']:.4f}")
        if best_metrics.get('roc_auc'):
            print(f"   ROC-AUC: {best_metrics['roc_auc']:.4f}")
    
    print(f"\nê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")
    print(f"ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    print("âœ… ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
    print("=" * 70)


if __name__ == "__main__":
    main()

