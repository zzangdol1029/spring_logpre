# prelog 프로젝트 개요

## 1. 프로젝트 목적

**prelog** 프로젝트는 **Spring Boot 애플리케이션의 로그 파일을 분석하여 이상 패턴을 자동으로 탐지**하는 시스템입니다.

### 주요 목표
- 로그 파일에서 **이상 패턴 자동 탐지**
- **심각도 평가**를 통한 우선순위 분류
- **다양한 딥러닝 모델 비교**를 통한 최적 모델 선정
- **실시간 이상 탐지** 가능한 모델 구축

### 활용 분야
- 시스템 모니터링 및 알림
- 장애 예방 및 조기 대응
- 로그 분석 자동화
- 운영 효율성 향상

---

## 2. 데이터셋 구성

### 2.1 데이터 소스
- **로그 파일 위치**: `pattern/prelog/logs/backup/`
- **로그 형식**: Spring Boot 표준 로그 형식
  ```
  2025-07-02 15:59:36.514  INFO 12185 --- [           main] k.r.b.f.c.Application : Starting...
  ```
- **로그 레벨**: INFO, DEBUG, TRACE, WARN, ERROR, FATAL

### 2.2 데이터 분할

현재 데이터셋은 다음과 같이 구성되어 있습니다:

| 데이터셋 | 전체 로그 | 정상 로그 | 에러 로그 | 비율 |
|---------|---------|----------|----------|------|
| **Train** | 31,900,000개 | 28,246,114개 | 3,653,886개 | 80% |
| **Valid** | 7,930,902개 | 7,025,679개 | 905,223개 | 20% |
| **Test** | 9,957,726개 | 9,232,124개 | 725,602개 | 20% |

**총 데이터**: 약 4,978만 개의 로그 라인

### 2.3 데이터 분할 방법

#### 방법 1: 메모리 내 분할 (소규모 데이터)
```python
# 전체 데이터를 메모리에 로드 후 분할
data = comparator.prepare_data(logs_df, train_ratio=0.8, valid_ratio=0.2)
```

#### 방법 2: 스트리밍 분할 (대규모 데이터, 권장)
```bash
# 파싱된 데이터를 청크 단위로 읽어서 분할
python log_specific_model_comparison.py \
    --load-parsed parsed_data.parquet \
    --streaming-split \
    --chunk-read-size 100000
```

**스트리밍 분할의 장점**:
- 메모리 효율적 (전체 데이터를 한 번에 로드하지 않음)
- 대용량 데이터 처리 가능
- 중간 결과를 파일로 저장하여 재사용 가능

### 2.4 데이터 분류 기준

#### 정상 로그
- **레벨**: INFO, DEBUG, TRACE
- **에러 키워드 없음**: Exception, Error, Failed 등이 없는 로그

#### 에러 로그
- **레벨**: WARN, ERROR, FATAL
- **에러 키워드 포함**: Exception, Error, Failed, Fatal, Critical 등

### 2.5 데이터 저장 형식

- **파싱 데이터**: `parsed_data.parquet` (Parquet 형식)
- **분할 데이터**: `split_data/` 디렉토리
  - `train.parquet`
  - `valid.parquet`
  - `test.parquet`
- **청크 파일**: `chunks/` 디렉토리 (선택적, 메모리 절약용)

---

## 3. 모델 선정 방법

### 3.1 사용 모델

프로젝트에서는 **3개의 로그 특화 이상 탐지 모델**을 비교합니다:

#### 1. **DeepLog** (LSTM 기반)
- **방식**: LSTM을 사용한 실행 경로 예측
- **특징**: 
  - 로그 시퀀스의 다음 로그를 예측
  - 예측 오차가 크면 이상으로 판단
  - 시계열 패턴 학습에 강함
- **장점**: 시퀀스 패턴 학습 능력 우수
- **단점**: 오탐 가능성 높음

#### 2. **LogAnomaly** (Template2Vec 기반)
- **방식**: 로그 템플릿을 벡터화하여 의미적 유사도 계산
- **특징**:
  - 로그 메시지를 템플릿으로 변환
  - Template2Vec으로 의미 벡터 생성
  - Z-score 기반 이상 탐지
- **장점**: 정확도 높음, 정상 로그 구분 능력 우수
- **단점**: 이상 탐지율 낮음 (False Negative 많음)

#### 3. **LogRobust** (Attention + Bi-LSTM)
- **방식**: Attention 메커니즘과 양방향 LSTM 결합
- **특징**:
  - 양방향 시퀀스 학습
  - Attention으로 중요한 부분 강조
  - 이상 점수 기반 탐지
- **장점**: 복잡한 패턴 학습 가능
- **단점**: 학습 시간 길고, 기본 임계값에서 실패 가능

### 3.2 모델 학습 방법

#### 학습 데이터
- **정상 로그만 사용**: 이상 탐지는 정상 패턴을 학습하여 이상을 찾는 방식
- **시퀀스 생성**: 연속된 로그를 시퀀스로 변환
  - DeepLog: 시퀀스 길이 10
  - LogAnomaly: 윈도우 크기 10
  - LogRobust: 시퀀스 길이 10

#### 학습 파라미터
```python
# 기본 설정
epochs = 5          # 빠른 학습용
batch_size = 128    # 빠른 학습용
learning_rate = 0.001

# 평가 모델 생성용 (권장)
epochs = 20
batch_size = 64
sample_size = 500000  # 학습 데이터 샘플링
```

### 3.3 모델 평가 방법

#### 평가 지표
1. **정확도 (Accuracy)**: 전체 예측 중 맞는 비율
2. **정밀도 (Precision)**: 이상으로 탐지한 것 중 실제 이상 비율
3. **재현율 (Recall)**: 실제 이상 중 탐지한 비율
4. **F1 점수**: 정밀도와 재현율의 조화 평균
5. **특이도 (Specificity)**: 정상을 정상으로 올바르게 구분
6. **ROC-AUC**: 수신자 조작 특성 곡선 아래 면적

#### 목표 성능 지표
| 지표 | 목표 | 설명 |
|------|------|------|
| 정확도 | **70% 이상** | 전체 예측 중 맞는 비율 |
| 정밀도 | **50% 이상** | 이상으로 탐지한 것 중 실제 이상 비율 |
| 재현율 | **60% 이상** | 실제 이상 중 탐지한 비율 |
| F1 점수 | **55% 이상** | 정밀도와 재현율의 조화 평균 |
| 특이도 | **80% 이상** | 정상을 정상으로 올바르게 구분 |

### 3.4 최적 모델 선정 방법

#### 종합 점수 계산
```python
weighted_score = (
    f1_score * 0.4 +      # F1 점수 40% (가장 중요)
    accuracy * 0.3 +       # 정확도 30%
    recall * 0.2 +         # 재현율 20%
    precision * 0.1        # 정밀도 10%
)
```

**가중치 기준**:
- **F1 점수 (40%)**: 정밀도와 재현율의 균형 (가장 중요)
- **정확도 (30%)**: 전체적인 예측 정확도
- **재현율 (20%)**: 이상을 놓치지 않는 능력
- **정밀도 (10%)**: 오탐을 줄이는 능력

#### 최적 임계값 탐색
`--optimize-threshold` 옵션을 사용하면:
1. 각 모델의 이상 점수 범위 확인
2. 100개의 임계값 후보 생성
3. 각 임계값에 대해 성능 지표 계산
4. 목표 성능 지표를 만족하는 임계값 중 최적값 선택
5. 최적 임계값으로 재평가

**사용 예시**:
```bash
python log_specific_model_comparison.py \
    --optimize-threshold \
    --target-accuracy 0.70 \
    --target-precision 0.50 \
    --target-recall 0.60 \
    --target-f1 0.55 \
    --target-specificity 0.80
```

### 3.5 모델 비교 결과

#### 비교 항목
1. **성능 지표 비교**: 정확도, 정밀도, 재현율, F1 점수, 특이도
2. **혼동 행렬**: True Positive, False Positive, True Negative, False Negative
3. **ROC 곡선**: 수신자 조작 특성 곡선
4. **심각도 분포**: CRITICAL, HIGH, MEDIUM, LOW
5. **종합 성능 레이더 차트**: 모든 지표를 한눈에 비교

#### 결과 저장
- **CSV 파일**: `log_specific_model_comparison.csv`
- **텍스트 리포트**: `comparison_report.txt`
- **그래프**: 
  - `performance_comparison.png` (막대 그래프)
  - `confusion_matrices.png` (혼동 행렬)
  - `roc_curves.png` (ROC 곡선)
  - `severity_distribution.png` (심각도 분포)
  - `performance_radar.png` (레이더 차트)

---

## 4. 프로젝트 구조

### 4.1 주요 파일

```
pattern/prelog/
├── log_anomaly_detector.py          # 로그 파서 및 기본 이상 탐지
├── log_specific_anomaly_detectors.py # 3개 모델 구현 (DeepLog, LogAnomaly, LogRobust)
├── log_specific_model_comparison.py  # 모델 비교 및 평가 시스템
├── severity_assessment.py            # 심각도 평가 시스템
├── train_from_chunks.py              # 청크 기반 학습 스크립트
├── run_full_pipeline.py              # 전체 파이프라인 실행 스크립트
├── parsed_data.parquet               # 파싱된 데이터 (재사용)
├── split_data/                       # 분할된 데이터셋
│   ├── train.parquet
│   ├── valid.parquet
│   └── test.parquet
├── chunks/                           # 청크 파일 (선택적)
└── results/                          # 결과 저장 폴더
    └── log_specific_comparison_*/    # 번호가 증가하는 결과 폴더
```

### 4.2 실행 워크플로우

#### 1단계: 로그 파싱
```bash
python log_specific_model_comparison.py --parse-only
```
- 로그 파일을 파싱하여 `parsed_data.parquet` 저장

#### 2단계: 데이터 분할
```bash
python log_specific_model_comparison.py \
    --load-parsed parsed_data.parquet \
    --streaming-split
```
- 파싱된 데이터를 Train/Valid/Test로 분할하여 `split_data/` 저장

#### 3단계: 모델 학습 및 평가
```bash
python log_specific_model_comparison.py \
    --load-split split_data \
    --optimize-threshold \
    --sample-size 500000 \
    --epochs 20 \
    --batch-size 64
```
- 3개 모델 학습 및 평가
- 최적 임계값 탐색
- 결과를 `results/log_specific_comparison_*/` 저장

#### 전체 파이프라인 (한 번에 실행)
```bash
python run_full_pipeline.py \
    --optimize-threshold \
    --sample-size 500000 \
    --epochs 20 \
    --batch-size 64
```

---

## 5. 성능 개선 방법

### 5.1 데이터 관련
- **더 많은 학습 데이터**: 20만개 → 50만개 이상
- **데이터 품질 향상**: 정상/에러 로그 분류 정확도 개선

### 5.2 학습 파라미터
- **더 많은 Epochs**: 10 → 20-30
- **적절한 Batch Size**: 64-128
- **Learning Rate 조정**: 0.001 → 0.0001 (더 안정적 학습)

### 5.3 임계값 최적화
- **`--optimize-threshold` 옵션 사용**: 항상 권장
- **목표 성능 지표 설정**: 실제 사용 목적에 맞게 조정

### 5.4 모델별 개선
- **DeepLog**: 임계값 높여서 오탐 감소
- **LogAnomaly**: 임계값 낮춰서 이상 탐지율 증가
- **LogRobust**: 모델 디버깅 및 하이퍼파라미터 튜닝

---

## 6. 참고 사항

### 6.1 메모리 최적화
- **스트리밍 분할 사용**: 대용량 데이터 처리 시 필수
- **청크 파일 활용**: 메모리 부족 시 청크 단위로 처리
- **데이터 샘플링**: 빠른 테스트 시 `--sample-size` 사용

### 6.2 실행 시간
- **빠른 테스트**: `--fast` 옵션 또는 `--sample-size 100000 --epochs 5`
- **평가 모델 생성**: `--sample-size 500000 --epochs 20 --optimize-threshold`
- **전체 데이터 학습**: `--sample-size` 제거, `--epochs 30`

### 6.3 결과 해석
- **종합 점수가 높은 모델**: 가장 우수한 모델
- **F1 점수**: 정밀도와 재현율의 균형 (가장 중요)
- **재현율이 높은 모델**: 이상을 놓치지 않음 (보안 중요 시)
- **정밀도가 높은 모델**: 오탐이 적음 (알림 중요 시)

---

## 7. 요약

### 프로젝트 목적
Spring Boot 로그 파일에서 이상 패턴을 자동으로 탐지하는 시스템

### 데이터셋
- 총 약 4,978만 개의 로그 라인
- Train/Valid/Test 비율: 80%/20%/20%
- 정상/에러 로그 분류 기준: 로그 레벨 및 에러 키워드

### 모델 선정
- **3개 모델 비교**: DeepLog, LogAnomaly, LogRobust
- **종합 점수 기반 선정**: F1 40%, Accuracy 30%, Recall 20%, Precision 10%
- **최적 임계값 탐색**: `--optimize-threshold` 옵션 사용

### 성능 목표
- 정확도: 70% 이상
- F1 점수: 55% 이상
- 재현율: 60% 이상
- 정밀도: 50% 이상
- 특이도: 80% 이상

